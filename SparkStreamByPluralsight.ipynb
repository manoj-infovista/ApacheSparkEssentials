{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNwcgWCwxn2v6PW7D8C+Rf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manojmanivannan/ApacheSparkEssentials/blob/master/SparkStreamByPluralsight.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Environment\n",
        "\n",
        "There is a need to change the default python version of colab from python3.8 to python3.7.\n",
        "\n",
        "The below cell should be run once and after it is complete , restart the runtime and run the rest (from 2nd cell onwards) of the cells"
      ],
      "metadata": {
        "id": "mRx8UBsWBsIC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsGAwnoOrBiO",
        "outputId": "14b05f19-153a-4a30-c80b-a3f6fe84383e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [Waiting for headers] [Waiting for headers] [1 InRelease 0 B/3,626 B 0%] [Co\r0% [Waiting for headers] [Waiting for headers] [Connected to developer.download\r                                                                               \rGet:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Waiting for headers] [2 InRelease 14.2 kB/88.7 kB 16%] [Connected to develo\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [2 InRelease 14.2 kB/88.7 k\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [2 InRelease 14.2 kB/88.7 k\r                                                                               \rGet:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "\r0% [1 InRelease gpgv 3,626 B] [4 InRelease 14.2 kB/88.7 kB 16%] [2 InRelease 34\r0% [1 InRelease gpgv 3,626 B] [4 InRelease 27.2 kB/88.7 kB 31%] [Waiting for he\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Connecting to ppa.launchpa\r                                                                               \rGet:5 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "\r0% [1 InRelease gpgv 3,626 B] [5 InRelease 9,844 B/83.3 kB 12%] [Waiting for he\r                                                                               \r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers]\r                                                                         \rHit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Connecting to ppa.launchpa\r                                                                               \rIgn:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Connecting to ppa.launchpa\r                                                                               \rGet:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,567 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,311 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [3,099 kB]\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,524 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,342 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,352 kB]\n",
            "Get:19 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [1,073 kB]\n",
            "Fetched 14.5 MB in 2s (7,849 kB/s)\n",
            "Reading package lists... Done\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n",
            "update-alternatives: using /usr/bin/python3.7 to provide /usr/bin/python3 (python3) in auto mode\n",
            "Python 3.7.16\n"
          ]
        }
      ],
      "source": [
        "!echo \"Python version before $(python --version)\"\n",
        "!apt-get update\n",
        "!apt-get install -y openjdk-8-jdk-headless scala jq  ssh python3.7 > /dev/null\n",
        "!if ! [[ -f \"spark-2.3.1-bin-hadoop2.7.tgz\" ]]; then wget -q http://archive.apache.org/dist/spark/spark-2.3.1/spark-2.3.1-bin-hadoop2.7.tgz; tar xf spark-2.3.1-bin-hadoop2.7.tgz; fi\n",
        "!if ! [[ -f \"ngrok-stable-linux-amd64.zip\" ]]; then wget -q https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip; unzip ngrok-stable-linux-amd64.zip; fi\n",
        "!if ! [[ -f \"goodls_linux_amd64\" ]]; then wget -q https://github.com/tanaikech/goodls/releases/download/v2.0.1/goodls_linux_amd64; chmod +x goodls_linux_amd64; fi\n",
        "!cat /etc/ssh/ssh_host_rsa_key.pub > /etc/ssh/authorized_keys\n",
        "\n",
        "#change alternatives\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 2\n",
        "\n",
        "#check python version\n",
        "!echo \"Python version after $(python --version)\"\n",
        "\n",
        "# install pip for new python \n",
        "!sudo apt-get install python3.7-distutils\n",
        "!wget https://bootstrap.pypa.io/get-pip.py\n",
        "!python get-pip.py\n",
        "\n",
        "# credit of these last two commands blongs to @Erik\n",
        "# install colab's dependencies\n",
        "!python -m pip install ipython ipython_genutils ipykernel jupyter_console prompt_toolkit httplib2 astor\n",
        "\n",
        "# link to the old google package\n",
        "!ln -s /usr/local/lib/python3.8/dist-packages/google /usr/local/lib/python3.7/dist-packages/google"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"export SPARK_HOME=/content/spark-2.3.1-bin-hadoop2.7\" >> /root/.bashrc\n",
        "!source /root/.bashrc"
      ],
      "metadata": {
        "id": "SkpU7ZiO7pBp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install findspark "
      ],
      "metadata": {
        "id": "bIOFcRNa6uW6",
        "outputId": "67821d15-7ab1-4e4f-cfa3-4d3b34d28cc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: findspark in /usr/local/lib/python3.7/dist-packages (2.0.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !export SPARK_HOME=\"/content/spark-2.3.1-bin-hadoop2.7\"\n",
        "# !export PATH=\"$PATH:$SPARK_HOME/bin\""
      ],
      "metadata": {
        "id": "SPFNXXLt1taQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.3.1-bin-hadoop2.7/\""
      ],
      "metadata": {
        "id": "No_o1zbR6SFK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/spark-2.3.1-bin-hadoop2.7/sbin/stop-master.sh\n",
        "!/content/spark-2.3.1-bin-hadoop2.7/sbin/stop-slave.sh\n",
        "!/content/spark-2.3.1-bin-hadoop2.7/sbin/start-master.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq9wGi622pMP",
        "outputId": "05b14acc-0d3f-4fa2-8be6-4d5cae29ce1b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stopping org.apache.spark.deploy.master.Master\n",
            "stopping org.apache.spark.deploy.worker.Worker\n",
            "starting org.apache.spark.deploy.master.Master, logging to /content/spark-2.3.1-bin-hadoop2.7//logs/spark--org.apache.spark.deploy.master.Master-1-b57710b1187d.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sleep 3 && grep -oP \"MasterUI' on port ([0-9]+)\" /content/spark-2.3.1-bin-hadoop2.7/logs/spark--org.apache.spark.deploy.master*.out \n",
        "!grep -oP \"spark:.*\" /content/spark-2.3.1-bin-hadoop2.7/logs/spark--org.apache.spark.deploy.master*.out "
      ],
      "metadata": {
        "id": "in0vBJz53fCA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca3658de-eaa8-4620-8c6f-96e3270a6dde"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MasterUI' on port 8081\n",
            "spark://b57710b1187d:7077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/spark-2.3.1-bin-hadoop2.7/sbin/start-slave.sh $(grep -oP \"spark:.*\" /content/spark-2.3.1-bin-hadoop2.7/logs/spark--org.apache.spark.deploy.master*.out)\n",
        "!sleep 3 && grep -oP \"WorkerUI' on port ([0-9]+)\" /content/spark-2.3.1-bin-hadoop2.7/logs/spark--org.apache.spark.deploy.worker*.out "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkkKXuq24Wy_",
        "outputId": "31edafff-22f1-4696-ba66-00fcd71a8254"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting org.apache.spark.deploy.worker.Worker, logging to /content/spark-2.3.1-bin-hadoop2.7//logs/spark--org.apache.spark.deploy.worker.Worker-1-b57710b1187d.out\n",
            "WorkerUI' on port 8082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok authtoken 2IeJHLKYs6eB68PKJQM1VkpPu00_5JXQQZW3hofy6Q6vqTX2')\n",
        "from time import sleep\n",
        "def ngrok_tunnel_by_port(port: int):\n",
        "  get_ipython().system_raw('pkill -f ngrok')\n",
        "  get_ipython().system_raw(f'./ngrok http {port} &')\n",
        "  sleep(4)\n",
        "  print(get_ipython().getoutput('curl -s http://localhost:4040/api/tunnels',split=True))\n",
        "\n"
      ],
      "metadata": {
        "id": "lLgtrEcd6Mgw",
        "outputId": "bab7776a-8c44-4573-db36-5075b7408487",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!jps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voP1B-tk0JZX",
        "outputId": "11000358-52be-4234-8c82-db0bf0b259df"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4001 Master\n",
            "4138 Jps\n",
            "4077 Worker\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "master_url = get_ipython().getoutput('grep -oP \"spark:.*\" /content/spark-2.3.1-bin-hadoop2.7/logs/spark--org.apache.spark.deploy.master*.out',split=True)\n",
        "print('Master URL:',master_url[0])\n",
        "# get_ipython().system_raw(f'nohup pyspark --master {master_url[0]} --num-executors 5 --driver-memory 4g --executor-memory 4g &' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mvm9h-tmG4g2",
        "outputId": "4c1f4d68-4fa5-4bcb-e33c-532b99ebb3a1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Master URL: spark://b57710b1187d:7077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!jps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFbNRUnkNkgz",
        "outputId": "03beb22f-3ce6-4e95-fbd5-3ee0974889bc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4001 Master\n",
            "4077 Worker\n",
            "4157 Jps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext, SparkConf\n",
        "\n",
        "# Spark session & context\n",
        "conf = SparkConf().set(\"spark.master\",master_url[0]).set('spark.ui.port', '4050').set(\"spark.driver.memory\",'4g').set(\"spark.executor.memory\",'4g')\n",
        "try:\n",
        "  # sc.stop()\n",
        "  sc = SparkContext(conf=conf)\n",
        "except ValueError:\n",
        "  sc.stop()\n",
        "  sc = SparkContext(conf=conf)\n",
        "\n",
        "spark = SparkSession.builder.appName('PluralSight').getOrCreate()"
      ],
      "metadata": {
        "id": "LVr5T3eaK2iG",
        "outputId": "c7208855-eb60-47bb-83d2-370ecaf7610e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-10 21:52:36 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "id": "z85g2iFl3ADR",
        "outputId": "ccf3a183-66d3-4501-f17e-91330a70ee19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f1a78204a50>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://b57710b1187d:4050\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v2.3.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>spark://b57710b1187d:7077</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok_tunnel_by_port(4050)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EIv6ZOvLtIh",
        "outputId": "ab39c8af-2037-4a4c-9a59-674f4420f11d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['{\"tunnels\":[{\"name\":\"command_line\",\"uri\":\"/api/tunnels/command_line\",\"public_url\":\"https://2bb1-34-86-129-231.ngrok.io\",\"proto\":\"https\",\"config\":{\"addr\":\"http://localhost:4050\",\"inspect\":true},\"metrics\":{\"conns\":{\"count\":0,\"gauge\":0,\"rate1\":0,\"rate5\":0,\"rate15\":0,\"p50\":0,\"p90\":0,\"p95\":0,\"p99\":0},\"http\":{\"count\":0,\"rate1\":0,\"rate5\":0,\"rate15\":0,\"p50\":0,\"p90\":0,\"p95\":0,\"p99\":0}}},{\"name\":\"command_line (http)\",\"uri\":\"/api/tunnels/command_line%20%28http%29\",\"public_url\":\"http://2bb1-34-86-129-231.ngrok.io\",\"proto\":\"http\",\"config\":{\"addr\":\"http://localhost:4050\",\"inspect\":true},\"metrics\":{\"conns\":{\"count\":0,\"gauge\":0,\"rate1\":0,\"rate5\":0,\"rate15\":0,\"p50\":0,\"p90\":0,\"p95\":0,\"p99\":0},\"http\":{\"count\":0,\"rate1\":0,\"rate5\":0,\"rate15\":0,\"p50\":0,\"p90\":0,\"p95\":0,\"p99\":0}}}],\"uri\":\"/api/tunnels\"}']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "happiness_df = spark.read.format('csv').option('header','true').load('2016.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hN-zVuhMD50",
        "outputId": "cb3ab3fd-07df-444e-ce40-ff072c875842"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "happiness_df.show(5)"
      ],
      "metadata": {
        "id": "5-9e75Yje1II",
        "outputId": "7d1a71ca-e379-4192-cfd8-71b79532f55c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------+--------------+---------------+-------------------------+-------------------------+------------------------+-------+------------------------+-------+-----------------------------+----------+-----------------+\n",
            "|    Country|        Region|Happiness Rank|Happiness Score|Lower Confidence Interval|Upper Confidence Interval|Economy (GDP per Capita)| Family|Health (Life Expectancy)|Freedom|Trust (Government Corruption)|Generosity|Dystopia Residual|\n",
            "+-----------+--------------+--------------+---------------+-------------------------+-------------------------+------------------------+-------+------------------------+-------+-----------------------------+----------+-----------------+\n",
            "|    Denmark|Western Europe|             1|          7.526|                     7.46|                    7.592|                 1.44178|1.16374|                 0.79504|0.57941|                      0.44453|   0.36171|          2.73939|\n",
            "|Switzerland|Western Europe|             2|          7.509|                    7.428|                     7.59|                 1.52733|1.14524|                 0.86303|0.58557|                      0.41203|   0.28083|          2.69463|\n",
            "|    Iceland|Western Europe|             3|          7.501|                    7.333|                    7.669|                 1.42666|1.18326|                 0.86733|0.56624|                      0.14975|   0.47678|          2.83137|\n",
            "|     Norway|Western Europe|             4|          7.498|                    7.421|                    7.575|                 1.57744| 1.1269|                 0.79579|0.59609|                      0.35776|   0.37895|          2.66465|\n",
            "|    Finland|Western Europe|             5|          7.413|                    7.351|                    7.475|                 1.40598|1.13464|                 0.81091|0.57104|                      0.41004|   0.25492|          2.82596|\n",
            "+-----------+--------------+--------------+---------------+-------------------------+-------------------------+------------------------+-------+------------------------+-------+-----------------------------+----------+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "happiness_df.select('Country','Region','Happiness Rank').show()"
      ],
      "metadata": {
        "id": "_7300TXUnCaL",
        "outputId": "d30af2ef-ba6d-48be-d09c-13a2f8e72036",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+--------------------+--------------+\n",
            "|      Country|              Region|Happiness Rank|\n",
            "+-------------+--------------------+--------------+\n",
            "|      Denmark|      Western Europe|             1|\n",
            "|  Switzerland|      Western Europe|             2|\n",
            "|      Iceland|      Western Europe|             3|\n",
            "|       Norway|      Western Europe|             4|\n",
            "|      Finland|      Western Europe|             5|\n",
            "|       Canada|       North America|             6|\n",
            "|  Netherlands|      Western Europe|             7|\n",
            "|  New Zealand|Australia and New...|             8|\n",
            "|    Australia|Australia and New...|             9|\n",
            "|       Sweden|      Western Europe|            10|\n",
            "|       Israel|Middle East and N...|            11|\n",
            "|      Austria|      Western Europe|            12|\n",
            "|United States|       North America|            13|\n",
            "|   Costa Rica|Latin America and...|            14|\n",
            "|  Puerto Rico|Latin America and...|            15|\n",
            "|      Germany|      Western Europe|            16|\n",
            "|       Brazil|Latin America and...|            17|\n",
            "|      Belgium|      Western Europe|            18|\n",
            "|      Ireland|      Western Europe|            19|\n",
            "|   Luxembourg|      Western Europe|            20|\n",
            "+-------------+--------------------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "happiness_df.select('Country','Region','Happiness Score')\\\n",
        "            .groupBy('Country')\\\n",
        "            .agg({'Happiness Score':'avg'})\\\n",
        "            .show(5)"
      ],
      "metadata": {
        "id": "nMFEb9seCmtb",
        "outputId": "2f33e6db-dcfc-4198-80cb-119af245c1d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+\n",
            "| Country|avg(Happiness Score)|\n",
            "+--------+--------------------+\n",
            "|    Chad|               3.763|\n",
            "|  Russia|               5.856|\n",
            "|Paraguay|               5.538|\n",
            "|   Yemen|               3.724|\n",
            "| Senegal|               4.219|\n",
            "+--------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc.stop()"
      ],
      "metadata": {
        "id": "oy7tz7f8DBTn"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# High Availability setup using ZOOKEEPER"
      ],
      "metadata": {
        "id": "v2MhmEmUIE_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"export SPARK_DAEMON_JAVA_OPTS=\\\"-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=localhost:2181\\\"\" > $SPARK_HOME/conf/ha.conf\n",
        "!cat $SPARK_HOME/conf/ha.conf"
      ],
      "metadata": {
        "id": "cv1bQnmnDyOM",
        "outputId": "48a73dd0-7a12-498c-bb26-68a4bfb2036e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "export SPARK_DAEMON_JAVA_OPTS=\"-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=localhost:2181\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp $SPARK_HOME/sbin/start-master{,-2}.sh"
      ],
      "metadata": {
        "id": "bJni0K3JD120"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!$SPARK_HOME/sbin/stop-master.sh\n",
        "!$SPARK_HOME/sbin/start-master.sh -h localhost -p 7077 --webui-port 8081 --properties-file  $SPARK_HOME/conf/ha.conf"
      ],
      "metadata": {
        "id": "VGT8jL2SFuVL",
        "outputId": "1e6a612f-2ba6-4fc3-98a9-774d54560b65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stopping org.apache.spark.deploy.master.Master\n",
            "starting org.apache.spark.deploy.master.Master, logging to /content/spark-2.3.1-bin-hadoop2.7//logs/spark--org.apache.spark.deploy.master.Master-1-b57710b1187d.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!grep 'CLASS 1' $SPARK_HOME/sbin/start-master-2.sh\n",
        "!sed -i -e 's/CLASS 1/CLASS 2/' $SPARK_HOME/sbin/start-master-2.sh"
      ],
      "metadata": {
        "id": "EAa3McRMFxR7",
        "outputId": "0601636a-25de-489e-a50b-6160c692477a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"${SPARK_HOME}/sbin\"/spark-daemon.sh start $CLASS 1 \\\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!$SPARK_HOME/sbin/start-master-2.sh -h localhost -p 17077 --webui-port 18081 --properties-file  $SPARK_HOME/conf/ha.conf"
      ],
      "metadata": {
        "id": "ItLI0sCJGLkS",
        "outputId": "aed3f9cb-76fc-4f7d-9f0e-9efeddcb3559",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting org.apache.spark.deploy.master.Master, logging to /content/spark-2.3.1-bin-hadoop2.7//logs/spark--org.apache.spark.deploy.master.Master-2-b57710b1187d.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!jps -lm"
      ],
      "metadata": {
        "id": "L41s_pnbGfeQ",
        "outputId": "5cd5d981-8e4e-488f-d06a-2db05c642b7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4705 org.apache.spark.deploy.master.Master --host b57710b1187d --port 7077 --webui-port 8080 -h localhost -p 17077 --webui-port 18081 --properties-file /content/spark-2.3.1-bin-hadoop2.7//conf/ha.conf\n",
            "4595 org.apache.spark.deploy.master.Master --host b57710b1187d --port 7077 --webui-port 8080 -h localhost -p 7077 --webui-port 8081 --properties-file /content/spark-2.3.1-bin-hadoop2.7//conf/ha.conf\n",
            "4772 jdk.jcmd/sun.tools.jps.Jps -lm\n",
            "4077 org.apache.spark.deploy.worker.Worker --webui-port 8081 spark://b57710b1187d:7077\n",
            "4175 org.apache.spark.deploy.SparkSubmit --conf spark.executor.memory=4g --conf spark.master=spark://b57710b1187d:7077 --conf spark.driver.memory=4g --conf spark.ui.port=4050 pyspark-shell\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!grep -oP \"spark:.*\" $SPARK_HOME/logs/spark--org.apache.spark.deploy.master*.out"
      ],
      "metadata": {
        "id": "a3X1ToVaGotM",
        "outputId": "72309395-99be-4079-8dad-1ef68b8fecf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/spark-2.3.1-bin-hadoop2.7/logs/spark--org.apache.spark.deploy.master.Master-1-b57710b1187d.out:spark://localhost:7077\n",
            "/content/spark-2.3.1-bin-hadoop2.7/logs/spark--org.apache.spark.deploy.master.Master-2-b57710b1187d.out:spark://localhost:17077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!$SPARK_HOME/sbin/stop-slave.sh\n",
        "!$SPARK_HOME/sbin/start-slave.sh --webui-port 8082 spark://localhost:7077,localhost:17077"
      ],
      "metadata": {
        "id": "cMe5a37VG0lL",
        "outputId": "6b5a020d-0630-4660-ee68-28256d00f58c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no org.apache.spark.deploy.worker.Worker to stop\n",
            "starting org.apache.spark.deploy.worker.Worker, logging to /content/spark-2.3.1-bin-hadoop2.7//logs/spark--org.apache.spark.deploy.worker.Worker-1-b57710b1187d.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok_tunnel_by_port(18081)"
      ],
      "metadata": {
        "id": "U1U9Tr26HoMz",
        "outputId": "f9f32d82-bc03-4124-b979-dbd2a0f9a870",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['{\"tunnels\":[{\"name\":\"command_line\",\"uri\":\"/api/tunnels/command_line\",\"public_url\":\"https://2f7b-34-86-129-231.ngrok.io\",\"proto\":\"https\",\"config\":{\"addr\":\"http://localhost:18081\",\"inspect\":true},\"metrics\":{\"conns\":{\"count\":0,\"gauge\":0,\"rate1\":0,\"rate5\":0,\"rate15\":0,\"p50\":0,\"p90\":0,\"p95\":0,\"p99\":0},\"http\":{\"count\":0,\"rate1\":0,\"rate5\":0,\"rate15\":0,\"p50\":0,\"p90\":0,\"p95\":0,\"p99\":0}}},{\"name\":\"command_line (http)\",\"uri\":\"/api/tunnels/command_line%20%28http%29\",\"public_url\":\"http://2f7b-34-86-129-231.ngrok.io\",\"proto\":\"http\",\"config\":{\"addr\":\"http://localhost:18081\",\"inspect\":true},\"metrics\":{\"conns\":{\"count\":0,\"gauge\":0,\"rate1\":0,\"rate5\":0,\"rate15\":0,\"p50\":0,\"p90\":0,\"p95\":0,\"p99\":0},\"http\":{\"count\":0,\"rate1\":0,\"rate5\":0,\"rate15\":0,\"p50\":0,\"p90\":0,\"p95\":0,\"p99\":0}}}],\"uri\":\"/api/tunnels\"}']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext, SparkConf\n",
        "\n",
        "# Spark session & context\n",
        "conf = SparkConf().set(\"spark.master\",\"spark://localhost:7077,localhost:17077\").set('spark.ui.port', '4050').set(\"spark.driver.memory\",'4g').set(\"spark.executor.memory\",'4g')\n",
        "try:\n",
        "  # sc.stop()\n",
        "  sc = SparkContext(conf=conf)\n",
        "except ValueError:\n",
        "  sc.stop()\n",
        "  sc = SparkContext(conf=conf)\n",
        "\n",
        "spark = SparkSession.builder.appName('PluralSight').getOrCreate()"
      ],
      "metadata": {
        "id": "e-GYNEfcH2yg"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok_tunnel_by_port(8081)"
      ],
      "metadata": {
        "id": "Ddl_SvihIcKo",
        "outputId": "21566204-46c6-4b76-ead4-e41dc2481510",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['{\"tunnels\":[{\"name\":\"command_line\",\"uri\":\"/api/tunnels/command_line\",\"public_url\":\"https://8d09-34-86-129-231.ngrok.io\",\"proto\":\"https\",\"config\":{\"addr\":\"http://localhost:8081\",\"inspect\":true},\"metrics\":{\"conns\":{\"count\":0,\"gauge\":0,\"rate1\":0,\"rate5\":0,\"rate15\":0,\"p50\":0,\"p90\":0,\"p95\":0,\"p99\":0},\"http\":{\"count\":0,\"rate1\":0,\"rate5\":0,\"rate15\":0,\"p50\":0,\"p90\":0,\"p95\":0,\"p99\":0}}},{\"name\":\"command_line (http)\",\"uri\":\"/api/tunnels/command_line%20%28http%29\",\"public_url\":\"http://8d09-34-86-129-231.ngrok.io\",\"proto\":\"http\",\"config\":{\"addr\":\"http://localhost:8081\",\"inspect\":true},\"metrics\":{\"conns\":{\"count\":0,\"gauge\":0,\"rate1\":0,\"rate5\":0,\"rate15\":0,\"p50\":0,\"p90\":0,\"p95\":0,\"p99\":0},\"http\":{\"count\":0,\"rate1\":0,\"rate5\":0,\"rate15\":0,\"p50\":0,\"p90\":0,\"p95\":0,\"p99\":0}}}],\"uri\":\"/api/tunnels\"}']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "happiness_df = spark.read.format('csv').option('header','true').load('2016.csv')"
      ],
      "metadata": {
        "id": "l9Q7fg8UIhBf",
        "outputId": "4fa26944-af9b-4c42-c2a2-125c1a053619",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!jps"
      ],
      "metadata": {
        "id": "FwD8uiLvIt1h",
        "outputId": "cb4fe788-26fb-4d61-e7dd-7cfabba2b79f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4705 Master\n",
            "4595 Master\n",
            "5157 CoarseGrainedExecutorBackend\n",
            "5017 Worker\n",
            "5228 Jps\n",
            "4175 SparkSubmit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# kill one of the master\n",
        "!kill -9 4705 "
      ],
      "metadata": {
        "id": "ysdq0umgI0t0",
        "outputId": "72e2313c-4d7e-4f31-8390-2b15018443f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-10 22:25:34 ERROR TaskSchedulerImpl:70 - Lost executor 0 on 172.28.0.12: java.io.IOException: Failed to create directory /content/spark-2.3.1-bin-hadoop2.7/work/app-20221210222245-0000/0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "happiness_df.select('Country','Region','Happiness Rank').show()"
      ],
      "metadata": {
        "id": "hIBbhYuiJFdh",
        "outputId": "292281dd-2d82-47e0-d9a8-c02a70ade0df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Stage 1:>                                                          (0 + 1) / 1]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+--------------------+--------------+\n",
            "|      Country|              Region|Happiness Rank|\n",
            "+-------------+--------------------+--------------+\n",
            "|      Denmark|      Western Europe|             1|\n",
            "|  Switzerland|      Western Europe|             2|\n",
            "|      Iceland|      Western Europe|             3|\n",
            "|       Norway|      Western Europe|             4|\n",
            "|      Finland|      Western Europe|             5|\n",
            "|       Canada|       North America|             6|\n",
            "|  Netherlands|      Western Europe|             7|\n",
            "|  New Zealand|Australia and New...|             8|\n",
            "|    Australia|Australia and New...|             9|\n",
            "|       Sweden|      Western Europe|            10|\n",
            "|       Israel|Middle East and N...|            11|\n",
            "|      Austria|      Western Europe|            12|\n",
            "|United States|       North America|            13|\n",
            "|   Costa Rica|Latin America and...|            14|\n",
            "|  Puerto Rico|Latin America and...|            15|\n",
            "|      Germany|      Western Europe|            16|\n",
            "|       Brazil|Latin America and...|            17|\n",
            "|      Belgium|      Western Europe|            18|\n",
            "|      Ireland|      Western Europe|            19|\n",
            "|   Luxembourg|      Western Europe|            20|\n",
            "+-------------+--------------------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r                                                                                \r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2tQcUiXfJWri"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}