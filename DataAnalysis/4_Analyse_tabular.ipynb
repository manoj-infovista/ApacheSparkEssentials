{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Tabular Data\n",
    "\n",
    "Unlike previous notebooks where we dealt with unstructure textual data, here we will go into structed data. We will focus on `SparkReader` object for delimited data rather than unstructured text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily create a data frame from the data in our program with the spark\n",
    "`.createDataFrame` function, as below. Our first parameter is the data itself. You can provide a list of items (here, a list of lists), a pandas data frame, or a resilient distributed dataset. The second parameter is the schema of the data frame. Here we are passing a list of column names which is sufficient for PySpark as it will infer the types (string, long, and double, respectively) of our columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Item: string (nullable = true)\n",
      " |-- Quantity: long (nullable = true)\n",
      " |-- Price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_grocery_list = [\n",
    "    [\"Banana\", 2, 1.74],\n",
    "    [\"Apple\", 4, 2.04],\n",
    "    [\"Carrot\", 1, 1.09],\n",
    "    [\"Cake\", 1, 10.99],\n",
    "]\n",
    "\n",
    "df_grocery_list = spark.createDataFrame(\n",
    "    my_grocery_list, [\"Item\",\"Quantity\",\"Price\"]\n",
    ")\n",
    "\n",
    "df_grocery_list.printSchema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "PySpark doesn’t provide any charting capabilities and doesn’t play with other charting libraries (like `Matplotlib`, `seaborn`, `Altair`, or `plot.ly`), and this makes a lot of sense: PySpark distributes your data over many computers. It doesn’t make much sense to distribute a chart creation. The usual solution will be to transform your data using PySpark, use the `toPandas()` method to transform your PySpark data frame into a pandas data frame, and then use your favorite charting library. \n",
    "\n",
    "When using toPandas(), remember that you lose the advantages of working with multiple machines, as the data will accumulate on the driver. Reserve this operation for an aggregated or manageable data set. \n",
    "\n",
    "A general rule of thumb is if $\\#\\ of\\ rows\\ $ x $\\ \\#\\ of\\ columns\\ =\\ 100,000$ for 16GB driver, its better to reduce the data size further."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset** we are using is CRTC (Canadian Radio-Television and Telecommunications Commission). Every broadcaster is mandated to provide a complete log of the programs and commercials showcased to the Canadian public.\n",
    "\n",
    "we will try to answer this question *\"What are the channels with the greatest and least proportion of commercials ?\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05de79a9bc4beb95fb2b07d395d8e3fe55e6d8497bda19361fbfb16b724883dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
