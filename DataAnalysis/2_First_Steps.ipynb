{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Steps\n",
    "### A Simple Program in PySpark\n",
    "\n",
    "Data-driven applications, no matter how complex, all boil down to what we can\n",
    "think of as three meta steps, which are easy to distinguish in a program:\n",
    "1. We start by loading or reading the data we wish to work with.\n",
    "2. We transform the data, either via a few simple instructions or a very complex\n",
    "machine learning model.\n",
    "3. We then export (or sink) the resulting data, either into a file or by summarizing our findings into a visualization."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: \n",
    "> This is assumes you have Spark and Java installed and setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run spark interactively in terminal, run below commands in terminal\n",
    "- `set PYSPARK_DRIVER_PYTHON=ipython`\n",
    "- `set PYSPARK_DRIVER_PYTHON_OPTS=`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the pyspark REPL\n",
    "\n",
    "```\n",
    ">pyspark\n",
    "\n",
    "Python 3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]        \n",
    "Type 'copyright', 'credits' or 'license' for more information\n",
    "IPython 8.7.0 -- An enhanced Interactive Python. Type '?' for help.\n",
    "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
    "Setting default log level to \"WARN\".\n",
    "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).   \n",
    "23/01/02 22:24:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
    "Welcome to\n",
    "      ____              __\n",
    "     / __/__  ___ _____/ /__\n",
    "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
    "   /__ / .__/\\_,_/_/ /_/\\_\\   version 3.2.3\n",
    "      /_/\n",
    "\n",
    "Using Python version 3.8.10 (tags/v3.8.10:3d8993a, May  3 2021 11:48:03)\n",
    "Spark context Web UI available at http://ManojZephyrusG15:4040\n",
    "Spark context available as 'sc' (master = local[*], app id = local-1672694655134).\n",
    "SparkSession available as 'spark'.\n",
    "\n",
    "In [1]:\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SparkSession entry point\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession\\\n",
    "            .builder\\\n",
    "            .appName(\"Analyzing the vocabulary of Pride and Prejudice.\")\\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ManojZephyrusG15:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Analyzing the vocabulary of Pride and Prejudice.</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=Analyzing the vocabulary of Pride and Prejudice.>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading older PySpark code\n",
    "sc = spark.sparkContext\n",
    "sqlContext = spark\n",
    "sc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple problem: “What are the most popular words used in the English language?”\n",
    "\n",
    "Steps to carry out:\n",
    "1. *Read*—Read the input data (we’re assuming a plain text file).\n",
    "2. *Token*—Tokenize each word.\n",
    "3. *Clean*—Remove any punctuation and/or tokens that aren’t words. Lowercase\n",
    "each word.\n",
    "4. *Count*—Count the frequency of each word present in the text.\n",
    "5. *Answer*—Return the top 10 (or 20, 50, 100)\n",
    "\n",
    "![A simple program](images/first_steps_simple_program.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest and Explore\n",
    "\n",
    "we need to choose how we are going to store the ingested data. PySpark provides two main structures:\n",
    "1. RDD\n",
    "2. Data frame\n",
    "\n",
    "The **RDD** is like a distributed collection of objects (or rows). You pass orders to the RDD through regular Python functions over the items in it.\n",
    "\n",
    "The **data frame**  is a stricter version of the RDD. Conceptually, you can think of it like a table, where each cell can contain one value. The data frame makes heavy usage of the concept of columns, where you operate on columns instead of on records, like in the *RDD*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05de79a9bc4beb95fb2b07d395d8e3fe55e6d8497bda19361fbfb16b724883dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
